---
title: "Bootstrap Match Groups and Display Descriptive Statistics"
output: pdf_document
---

# Participant Characteristics
We used a bootstrap procedure to match diagnostic groups. We matched groups based on PLS-5 Auditory Comprehension raw scores, with a caliper of 5 points. Group differences are quantified with Cohen's *d*, variance ratio (ASD divided by NT), and *p*-values. We used a two-sample, two-tailed *t*-test to obtain *p*-values, unless either diagnostic group's distribution failed the Shapiro-Wilk normality test, in which case we used a Wilcoxon test.

```{r, echo=FALSE, message=FALSE, warning=FALSE, error=FALSE}
# Clear R environment
rm(list = ls(all = TRUE))

# Load libraries
library(readxl)
library(dplyr)
library(kableExtra)
library(knitr)

# Install and load bootmatch package
library(remotes)
remotes::install_github("tjmahr/bootmatch")
library(bootmatch)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE, error=FALSE}
# Compare standardized test measures across groups
compare_matched_groups <- function(input_df, metrics_to_compare) {
  desc <- data.frame(length(metrics_to_compare))
  metrics_list <- c(unique(metrics_to_compare))
  desc$Score <- c(metrics_list)
  for (i in seq_along(metrics_to_compare)) {
    test_scores <- dplyr::select(input_df, group, metrics_to_compare[i])
    test_scores <- na.omit(test_scores)
    asd_scores <- test_scores[test_scores$group == "ASD", ]
    td_scores <- test_scores[test_scores$group == "TD", ]

    # Calculate descriptive statistics for ASD group
    desc$ASD_n[i] <- c(nrow(asd_scores))
    desc$ASD_mean[i] <- c(round(mean(asd_scores[, 2])), 2)
    desc$ASD_sd[i] <- c(round(sd(asd_scores[, 2])), 2)
    desc$ASD_min[i] <- c(round(min(asd_scores[, 2])), 2)
    desc$ASD_max[i] <- c(round(max(asd_scores[, 2])), 2)

    # Calculate descriptive statistics for TD group
    desc$TD_n[i] <- c(nrow(td_scores))
    desc$TD_mean[i] <- c(round(mean(td_scores[, 2])), 2)
    desc$TD_sd[i] <- c(round(sd(td_scores[, 2])), 2)
    desc$TD_min[i] <- c(round(min(td_scores[, 2])), 2)
    desc$TD_max[i] <- c(round(max(td_scores[, 2])), 2)

    # Calculate effect size (Cohen's d)
    d <- effsize::cohen.d(asd_scores[[2]], td_scores[[2]], paired = FALSE)
    desc$d[i] <- abs(round(d$estimate, digits = 2))

    # Calculate variance ratio
    desc$v[i] <- round(var(asd_scores[[2]]) / var(td_scores[[2]]), digits = 2)

    # Test for normality
    test1 <- try(shapiro.test(as.numeric(asd_scores[[2]])), silent = TRUE)
    test2 <- try(shapiro.test(as.numeric(td_scores[[2]])), silent = TRUE)

    # If either distribution is non-normal, use a wilcox test, else use a t-test
    if (test1$p.value < 0.05 || test2$p.value < 0.05) {
      test <- try(
        wilcox.test(
          asd_scores[[2]],
          td_scores[[2]],
          paired = FALSE
        ),
        silent = TRUE
      )
      desc$p[i] <- ifelse(is(test, "try-error"), NA,
        round(as.numeric(test$p.value), 3)
      )
    } else {
      test <- try(
        t.test(
          asd_scores[[2]],
          td_scores[[2]],
          paired = FALSE
        ),
        silent = TRUE
      )
      desc$p[i] <- ifelse(is(test, "try-error"), NA,
        round(as.numeric(test$p.value), 3)
      )
    }
  }

  # Improve table legibility
  desc <- na.omit(desc)
  desc$p <- ifelse(desc$p < 0.001, "< 0.001", desc$p)
  colnames(desc)[1:14] <- c(
    "Measure", "N", "Mean", "SD", "Min", "Max",
    "N", "Mean", "SD", "Min", "Max",
    "Cohen's d", "Var Ratio", "p-value"
  )

  # Render table
  kable(desc, format = "latex", booktabs = TRUE, row.names = FALSE) %>%
    add_header_above(c(
      " " = 1,
      "ASD Group" = 5,
      "NT Group" = 5,
      "Group Differences" = 3
    ))
}
```

```{r, echo=FALSE, message=FALSE, warning=FALSE, error=FALSE}
# Define the raw GitHub URL of your Excel file
excel_url <- "https://github.com/tracyreuter/bootstrap-match-groups/raw/refs/heads/main/subjectlog.xlsx"

# Create a temporary file to download the Excel file
temp_file <- tempfile(fileext = ".xlsx")

# Download to the temporary file
download.file(excel_url, destfile = temp_file, mode = "wb")

# Load data
all_subjects <- read_excel(temp_file)
all_subjects <- dplyr::select(
  all_subjects, subject, group, sex, age,
  PLS.AC.Raw, PLS.AC.AE, PLS.EC.Raw, PLS.EC.AE,
  Mul.VR.Raw, Mul.VR.AE, Mul.Ratio.IQ
)

# Convert all metrics to numeric
all_subjects <- all_subjects %>% mutate_at(c(4:11), as.numeric)

# Match groups
foo <- boot_match_univariate(
  data = all_subjects,
  y = group,
  x = PLS.AC.Raw,
  id = subject,
  caliper = 5,
  boot = 100
)

# Subset to matched subjects
matched_subjects <- all_subjects %>%
  filter(subject %in% unique(foo$Matching_MatchID))
```

```{r, echo=FALSE, message=FALSE, warning=FALSE, error=FALSE, fig.width=6, fig.height=4, fig.align='center', results='asis'}
# Call function
compare_matched_groups(
  input_df = matched_subjects,
  metrics_to_compare = colnames(matched_subjects[4:11])
)
```